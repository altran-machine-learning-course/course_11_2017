{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize Data\n",
    "\n",
    "This notebook does not do much. It just has all the steps of Week2 and saves the traindata and test data in one place. This is very useful if you want to run several experments with multiple classifiers which use the same data.\n",
    "It helps not repeating redundant operations with feature handling. \n",
    "\n",
    "It would be useful to customize this. In order to do so keep note of the following :-\n",
    "* Modify which features to \"categorize\"\n",
    "* Modify which features to drop\n",
    "* Modify how to input missing data\n",
    "* Modify how to quantify the categorical values\n",
    "* Convert this into a module (maybe *datasethandler*?) which can :-\n",
    "    * Accept global parameters\n",
    "    * Cache data if the sub-dataset for the given parameters has already been computed\n",
    "    * [Optional] Paralellize\n",
    "    * [Optional] Make it dataset agnostic, so it will be able to download different kinds of datasets.\n",
    "    * _A dataset loader made in the above way is very useful to run hyperparameter experiments_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testdata.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "\n",
    "\n",
    "#Ignore Warnings - save some confusion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Pandas more columns\n",
    "pd.options.display.max_columns = None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Add input as import path\n",
    "sys.path.insert(0,'../input')\n",
    "\n",
    "# Plot style\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Import the data from the dataset\n",
    "train_data = pd.read_csv('../input/train.csv',index_col='id')\n",
    "test_data = pd.read_csv('../input/test.csv',index_col='id')\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.fare = df.fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.fare, bins, labels=group_names)\n",
    "    df.fare = categories\n",
    "    return df\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.cabin = df.cabin.fillna('N')\n",
    "    df.cabin = df.cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_name(df):\n",
    "    df['lname'] = df.name.apply(lambda x: x.split(' ')[0])\n",
    "    df['lname'].fillna(' ')\n",
    "    df['nameprefix'] = df.name.apply(lambda x: x.split(' ')[1])\n",
    "    df['nameprefix'].fillna(' ')\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_features(df):\n",
    "    return df.drop(['ticket', 'name', 'embarked', 'home.dest', 'body', 'boat'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_fares(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_data = transform_features(train_data)\n",
    "test_data  = transform_features(test_data)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['fare', 'cabin', 'sex', 'lname', 'nameprefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "\n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "\n",
    "train_data, test_data = encode_features(train_data, test_data)\n",
    "\n",
    "def fill_missing_data(df_train,df_test):\n",
    "    features = ['age']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    df_imputer = preprocessing.Imputer()\n",
    "    df_imputer.fit(df_combined[features])\n",
    "    df_train[features] = df_imputer.transform(df_train[features])\n",
    "    df_test[features] = df_imputer.transform(df_test[features])\n",
    "    return df_train, df_test\n",
    "\n",
    "train_data,test_data = fill_missing_data(train_data,test_data)\n",
    "\n",
    "def get_X_Y_pair(df):\n",
    "    features = df.columns.values\n",
    "    x_features = [f for f in features if f!='survived']\n",
    "    return df[x_features], df['survived']\n",
    "\n",
    "def scale_data(df_train, df_test):\n",
    "    df_combine = pd.concat([df_train, df_test])\n",
    "    features = df_train.columns.values\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    scaler.fit(df_combine)\n",
    "    return scaler.transform(df_train), scaler.transform(df_test)\n",
    "\n",
    "x_train, y_train = get_X_Y_pair(train_data)\n",
    "x_test, y_test = get_X_Y_pair(test_data)\n",
    "\n",
    "#not pandas after this\n",
    "x_train, x_test = scale_data(x_train,x_test)\n",
    "\n",
    "import joblib\n",
    "joblib.dump((x_train,y_train),\"traindata.pkl\")\n",
    "joblib.dump((x_test, y_test), \"testdata.pkl\")\n",
    "\n",
    "#import _pickle as pkl\n",
    "#pkl.dumps((x_test, y_test), open(\"testdata.pkl\",\"w\"))\n",
    "#pkl.dumps((x_train, y_train), open(\"traindata.pkl\",\"w\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

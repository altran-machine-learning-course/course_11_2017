{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Not? - Generative Adversarial Networks\n",
    "\n",
    "\n",
    "## What are Gans - wikipedia\n",
    "\n",
    "Generative adversarial networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks contesting with each other in a zero-sum game framework. They were introduced by Ian Goodfellow et al. in 2014. This technique can generate photographs that look at least superficially authentic to human observers, having many realistic characteristics (though in tests people can tell real from generated in many cases)\n",
    "\n",
    "More at : https://en.wikipedia.org/wiki/Generative_adversarial_network\n",
    "\n",
    "\n",
    "## Intuition\n",
    "\n",
    "![fakeWatches](resources/fake_watches.png)\n",
    "\n",
    "As people start identifying the fake-watch seller's watch to be fake, he improves them. Then better spotters identify the watches as fake, and he improves them further. This keeps going on till, at some point, there is nothing different between a fake watch and a real watch\n",
    "\n",
    "1. Learn a simple real vs fake classifier - with a small dataset\n",
    "2. Reward a generator to fake samples\n",
    "3. Reward discriminator to discriminate between fake and real.\n",
    "4. Keep repeating this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started \n",
    "\n",
    "### The Model View\n",
    "![GAN MODEL](resources/gan_model.jpeg)\n",
    "\n",
    "\n",
    "### The Library\n",
    "\n",
    "* Keras : Gives a very high level view of neural networks. \n",
    "* You can add and stack layers to your model easily\n",
    "* We will use the Keras + Tensorflow combination\n",
    "\n",
    "\n",
    "\n",
    "### First steps - Imports\n",
    "Lets also start a class definition. We will define the class in parts, and add some jupyter specific code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28 \n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator() # Some Magical function\n",
    "        self.discriminator.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator() # Another Magical Function\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity \n",
    "        self.combined = Model(z, valid) # Lets connect the two models\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "* Now that we have our general flow chart ready, let's start implementing those functions.\n",
    "* For the generator, we ideally want to start off with noise and generate an image.  \n",
    "* We stack a bunch of convolutional layers together, and do some upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(self):\n",
    "\n",
    "    noise_shape = (100,)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=noise_shape)\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)\n",
    "\n",
    "DCGAN.build_generator = build_generator #For jupyter -> disjointed classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "* Now that we have the structure and a generator, we need to build a discriminator which discriminates real from fake\n",
    "* We want to start with an image and output a real/fake decision\n",
    "* We stack a bunch of convolutional layers, starting from image dimensions, giving out a value (0/1 - real/fake)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(self):\n",
    "\n",
    "    img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)\n",
    "\n",
    "DCGAN.build_discriminator = build_discriminator # For jupyter - disjointed classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "* Now we have the two elements - A generator and a discriminator\n",
    "* It's time to run the training loop\n",
    "* Dataset : Mnist (A simple digits based dataset)\n",
    "* Batch Size : 128 by default\n",
    "* Pre-Steps\n",
    "    1. Load Data\n",
    "    2. Normalize Data\n",
    "* Steps\n",
    "    1. Select randomly some images from the dataset (0.5 times the batch size)\n",
    "    2. Generate the remaining(0.5 times batch size) images from noise\n",
    "    3. Train the discriminator\n",
    "        a. Real Images from dataset as 1\n",
    "        b. Fake images from generator as 0\n",
    "    4. Train the generator \n",
    "        a. Input is a full batch of noise\n",
    "        b. All these elements are treated as real (=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    half_batch = int(batch_size / 2)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        # Select a random half batch of images\n",
    "        idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "        imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a half batch of new images\n",
    "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator (real classified as ones and generated as zeros)\n",
    "        d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "        d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Generator\n",
    "        # ---------------------\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "        # Train the generator (wants discriminator to mistake images as real)\n",
    "        g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "        # Plot the progress\n",
    "        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % save_interval == 0:\n",
    "            self.save_imgs(epoch)\n",
    "\n",
    "DCGAN.train = train #jupter notebook class hack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run the entire loop\n",
    "\n",
    "And add in a small utility function to cache generated images every 50 batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 392,705\n",
      "Trainable params: 392,321\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,705\n",
      "Trainable params: 856,065\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def save_imgs(self, epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, 100))\n",
    "    gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"resources/images/mnist_%d.png\" % epoch)\n",
    "    plt.close()\n",
    "    \n",
    "DCGAN.save_imgs = save_imgs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=4000, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### So in the beginning we have shit :-\n",
    "![MNIST_0](resources/images/mnist_0.png)\n",
    "\n",
    "#### Then, it get's less shittier (epoch 1000): \n",
    "![MNIST_1000](resources/images/mnist_1000.png)\n",
    "\n",
    "\n",
    "#### Till shit get's awesome (epoch 7950)\n",
    "![MNIST_8000](resources/images/mnist_7950.png)\n",
    "\n",
    "#### All together\n",
    "![MNIST_Animated](resources/images/mnist_anim.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

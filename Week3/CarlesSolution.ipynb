{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta Techniques with classifiers\n",
    "\n",
    "In this session, we'll play around with classifiers, and techniques to optimize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - Imports and load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainData= [[ -1.54609786e+00  -1.34499549e+00   2.75868709e-16   4.81287772e-01\n",
      "   -4.44999502e-01  -1.56828509e+00   1.27192065e+00  -2.40989649e+00\n",
      "   -1.90080686e+00   5.98139336e-01   7.33522906e-02]]  with shape  (654, 11)\n",
      "TrainLables= id\n",
      "277    1\n",
      "Name: survived, dtype: int64 (654,)\n",
      "TestData= [[ 0.84191642 -1.34499549 -0.8449216   0.48128777 -0.4449995   0.53185321\n",
      "  -1.30008367  0.50783544  0.59567091 -0.719428    0.07335229]]  with shape  (655, 11)\n",
      "TestLabels= id\n",
      "621   NaN\n",
      "Name: survived, dtype: float64 (654,)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add input as import path\n",
    "sys.path.insert(0,'../input')\n",
    "\n",
    "import joblib #or your dataset handler\n",
    "X, Y = joblib.load(\"traindata.pkl\")\n",
    "X_test, Y_test = joblib.load(\"testdata.pkl\")\n",
    "\n",
    "#Double check if all is well\n",
    "print(\"TrainData=\",X[0:1],\" with shape \", X.shape)\n",
    "print(\"TrainLables=\", Y[0:1], Y.shape) \n",
    "\n",
    "print(\"TestData=\",X_test[0:1], \" with shape \",X_test.shape)\n",
    "print(\"TestLabels=\", Y_test[0:1], Y.shape) # We don't have test labels. Should be NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "# Initialize different models\n",
    "# Random_state 42 https://en.wikipedia.org/wiki/The_Hitchhiker%27s_Guide_to_the_Galaxy\n",
    "random_state=42\n",
    "multiple_classifier = []\n",
    "multiple_classifier.append(SVC(random_state=random_state))\n",
    "multiple_classifier.append(DecisionTreeClassifier(random_state=random_state))\n",
    "multiple_classifier.append(AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),learning_rate=0.1))\n",
    "multiple_classifier.append(RandomForestClassifier(random_state=random_state))\n",
    "multiple_classifier.append(ExtraTreesClassifier(random_state=random_state))\n",
    "multiple_classifier.append(GradientBoostingClassifier(random_state=random_state))\n",
    "multiple_classifier.append(MLPClassifier(random_state=random_state))\n",
    "multiple_classifier.append(KNeighborsClassifier())\n",
    "multiple_classifier.append(LogisticRegression(random_state=random_state))\n",
    "multiple_classifier.append(LinearDiscriminantAnalysis())\n",
    "\n",
    "cv_results = []\n",
    "for classifier in multiple_classifier :\n",
    "    cv_results.append(cross_val_score(classifier, X, y = Y, scoring = \"accuracy\", cv = StratifiedKFold(n_splits=10), n_jobs=4))\n",
    "\n",
    "cv_means = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_means.append(cv_result.mean())\n",
    "    cv_std.append(cv_result.std())\n",
    "\n",
    "cv_res = pd.DataFrame({\"CrossValMeans\":cv_means,\"CrossValerrors\": cv_std,\"Algorithm\":[\"SVC\",\"DecisionTree\",\"AdaBoost\",\n",
    "\"RandomForest\",\"ExtraTrees\",\"GradientBoosting\",\"MultipleLayerPerceptron\",\"KNeighboors\",\"LogisticRegression\",\"LinearDiscriminantAnalysis\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Algorithm  CrossValMeans  CrossValerrors\n",
      "0                         SVC       0.814895        0.044701\n",
      "1                DecisionTree       0.750653        0.046052\n",
      "2                    AdaBoost       0.758392        0.032068\n",
      "3                RandomForest       0.784406        0.049920\n",
      "4                  ExtraTrees       0.770629        0.047003\n",
      "5            GradientBoosting       0.801166        0.040181\n",
      "6     MultipleLayerPerceptron       0.808858        0.042147\n",
      "7                 KNeighboors       0.798112        0.032997\n",
      "8          LogisticRegression       0.785921        0.032841\n",
      "9  LinearDiscriminantAnalysis       0.787622        0.043737\n"
     ]
    }
   ],
   "source": [
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 54 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=4)]: Done 357 tasks      | elapsed:   27.7s\n",
      "[Parallel(n_jobs=4)]: Done 540 out of 540 | elapsed:   44.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest: 0.824159021407\n"
     ]
    }
   ],
   "source": [
    "# RandomForest Hyperparameter tuning\n",
    "random_forest = RandomForestClassifier()\n",
    "kfold = StratifiedKFold(n_splits=10)\n",
    "\n",
    "## Optimal parameters grid\n",
    "random_forest_params = {\"max_depth\": [None],\n",
    "                  \"max_features\": [1, 3, 10],\n",
    "                  \"min_samples_split\": [2, 3, 10],\n",
    "                  \"min_samples_leaf\": [1, 3, 10],\n",
    "                  \"bootstrap\": [False],\n",
    "                  \"n_estimators\" :[100, 300],\n",
    "                  \"criterion\": [\"gini\"]}\n",
    "\n",
    "\n",
    "opt_random_forest = GridSearchCV(random_forest,param_grid = random_forest_params, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose=2)\n",
    "opt_random_forest.fit(X,Y)\n",
    "opt_random_forest_best = opt_random_forest.best_estimator_\n",
    "\n",
    "# Best score\n",
    "print(\"random_forest:\", opt_random_forest.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 432 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done 530 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=4)]: Done 1530 tasks      | elapsed:   57.7s\n",
      "[Parallel(n_jobs=4)]: Done 2930 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 4320 out of 4320 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest: 0.804281345566\n"
     ]
    }
   ],
   "source": [
    "# Gradient boosting tunning\n",
    "\n",
    "gradient_boost = GradientBoostingClassifier()\n",
    "gradient_boost_params = {'loss' : [\"deviance\"],\n",
    "              'n_estimators' : [100, 200, 300, 500, 800, 1000],\n",
    "              'learning_rate': [0.1, 0.05, 0.01],\n",
    "              'max_depth': [4, 8, 16],\n",
    "              'min_samples_leaf': [150, 400, 100, 1000],\n",
    "              'max_features': [0.3, 0.1] \n",
    "              }\n",
    "\n",
    "opt_gradient_boost = GridSearchCV(gradient_boost,param_grid = gradient_boost_params, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "opt_gradient_boost.fit(X,Y)\n",
    "opt_gradient_boost_best = opt_gradient_boost.best_estimator_\n",
    "\n",
    "# Best score\n",
    "print(\"random_forest:\", opt_gradient_boost.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4)]: Done 280 out of 280 | elapsed:   18.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8165137614678899"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### SVC tunning\n",
    "svc = SVC(probability=True)\n",
    "svc_params = {'kernel': ['rbf'], \n",
    "                  'gamma': [ 0.001, 0.01, 0.1, 1],\n",
    "                  'C': [1, 10, 50, 100,200,300, 1000]}\n",
    "\n",
    "opt_svc = GridSearchCV(svc,param_grid = svc_params, cv=kfold, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n",
    "\n",
    "opt_svc.fit(X,Y)\n",
    "\n",
    "opt_svc_best = opt_svc.best_estimator_\n",
    "\n",
    "# Best score\n",
    "opt_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VotingClassifier' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-31fa74020864>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvoting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvoting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'VotingClassifier' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "voting = VotingClassifier(estimators=[('svc', opt_svc), ('gb', opt_gradient_boost), ('rf', opt_random_forest)], voting='soft', n_jobs=4)\n",
    "\n",
    "voting = voting.fit(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803053435115\n",
      "0.793893129771\n",
      "0.806106870229\n",
      "0.798473282443\n"
     ]
    }
   ],
   "source": [
    "from utils import accuracy_score_numpy\n",
    "\n",
    "# Ensemble\n",
    "Y_test = voting.predict(X_test)\n",
    "print(accuracy_score_numpy(Y_test))\n",
    "\n",
    "# opt_svc\n",
    "Y_test = opt_svc.predict(X_test)\n",
    "print(accuracy_score_numpy(Y_test))\n",
    "\n",
    "# opt_random_forest\n",
    "Y_test = opt_random_forest.predict(X_test)\n",
    "print(accuracy_score_numpy(Y_test))\n",
    "\n",
    "# opt_gradient_boost\n",
    "Y_test = opt_gradient_boost.predict(X_test)\n",
    "print(accuracy_score_numpy(Y_test))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
